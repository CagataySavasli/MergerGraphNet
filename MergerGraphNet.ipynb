{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-18T19:19:35.391146Z",
     "start_time": "2025-03-18T19:19:32.105805Z"
    }
   },
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from lib.util.graph_data_loader import GraphDataLoader\n",
    "from lib.model.graph_classifer import GraphClassifier, GraphResidualClassifier, GraphLSTMClassifier, GraphTransClassifier\n",
    "from lib.config.config_loader import ConfigLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = ConfigLoader().load_config()\n",
    "tqdm.pandas()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cagatay/.cache/pypoetry/virtualenvs/mergergraphnet-5CuCFj11-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T19:19:35.398645Z",
     "start_time": "2025-03-18T19:19:35.396317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dim = config['models']['input_dim']\n",
    "hidden_dim_1 = config['models']['hidden_dim_1']\n",
    "hidden_dim_2 = config['models']['hidden_dim_2']\n",
    "hidden_dim_3 = config['models']['hidden_dim_3']"
   ],
   "id": "ea387a806b1a9334",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T19:20:16.475837Z",
     "start_time": "2025-03-18T19:19:35.458627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('./data/processed/reports_labeled.csv')\n",
    "\n",
    "# df = df.loc[:100].copy()\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['sentences'] = df['mda'].progress_apply(lambda x: sent_tokenize(x))\n",
    "\n",
    "# train_df = df.loc[:80].copy().reset_index(drop=True)\n",
    "# test_df = df.loc[80:].copy().reset_index(drop=True)\n",
    "\n",
    "train_df = df[df['year'] <= 2019].copy().reset_index(drop=True)\n",
    "test_df = df[df['year'] > 2019].copy().reset_index(drop=True)\n",
    "\n",
    "merge_class_weight = len(train_df) / len(train_df[train_df['label'] == 1]['label'])\n",
    "not_merge_class_weight = len(train_df) / len(train_df[train_df['label'] == 0]['label'])\n",
    "\n",
    "class_weights = torch.tensor([merge_class_weight, not_merge_class_weight], dtype=torch.float).to(device)"
   ],
   "id": "a75b4db49f3b8c85",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13017/13017 [00:36<00:00, 360.24it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T19:20:16.548885Z",
     "start_time": "2025-03-18T19:20:16.543527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\"\"\n",
    "## Length of dataset:\n",
    "Length of training set: {len(train_df)}\n",
    "Length of test set: {len(test_df)}\n",
    "\n",
    "## Distribution of label:\n",
    "Number of merge in training set: {len(train_df[train_df['label'] == 1]['label'])}\n",
    "Number of not-merge in training set: {len(train_df[train_df['label'] == 0]['label'])}\n",
    "Class weights: {class_weights}\n",
    "\n",
    "Number of merge in test set: {len(test_df[test_df['label'] == 1]['label'])}\n",
    "Number of not-merge in test set: {len(test_df[test_df['label'] == 0]['label'])}\n",
    "\"\"\")"
   ],
   "id": "6590ae799be79df0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Length of dataset:\n",
      "Length of training set: 11019\n",
      "Length of test set: 1998\n",
      "\n",
      "## Distribution of label:\n",
      "Number of merge in training set: 1874\n",
      "Number of not-merge in training set: 9145\n",
      "Class weights: tensor([5.8799, 1.2049], device='cuda:0')\n",
      "\n",
      "Number of merge in test set: 302\n",
      "Number of not-merge in test set: 1696\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T19:21:43.433519Z",
     "start_time": "2025-03-18T19:20:16.556837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_corpus = [sentence for sentences in train_df['sentences'] for sentence in sentences]\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=input_dim, stop_words='english')\n",
    "vectorizer.fit(train_corpus)\n",
    "\n",
    "def get_tfidf_embeddings(sentence_list):\n",
    "    if not type(sentence_list) == list:\n",
    "        sentence_list = [sentence_list]\n",
    "    embeddings = vectorizer.transform(sentence_list)\n",
    "    return embeddings\n",
    "\n",
    "print(\"Train Sentence: \")\n",
    "train_df['tfidf_sentence'] = train_df['sentences'].progress_apply(get_tfidf_embeddings)\n",
    "print(\"Test Sentence: \")\n",
    "test_df['tfidf_sentence'] = test_df['sentences'].progress_apply(get_tfidf_embeddings)"
   ],
   "id": "ac63a0b3fb882b1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sentence: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11019/11019 [00:41<00:00, 263.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentence: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1998/1998 [00:07<00:00, 275.19it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T19:34:40.277611Z",
     "start_time": "2025-03-18T19:34:40.268238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = GraphDataLoader(train_df, 5)\n",
    "test_dataset = GraphDataLoader(test_df, 5)"
   ],
   "id": "8b1c23d623f35072",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T19:34:40.825989Z",
     "start_time": "2025-03-18T19:34:40.821522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ],
   "id": "8190fe0c9645242e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T19:34:41.459611Z",
     "start_time": "2025-03-18T19:34:41.452191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    accuracy = round(accuracy_score(y_true, y_pred), 4)\n",
    "    precision = round(precision_score(y_true, y_pred, zero_division=0), 4)\n",
    "    recall = round(recall_score(y_true, y_pred, zero_division=0), 4)\n",
    "    f1 = round(f1_score(y_true, y_pred, zero_division=0), 4)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    return accuracy, precision, recall, f1, tp, tn, fp, fn\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    # train_loader üzerinden geçerken progress bar ekleniyor.\n",
    "    for data, label in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        label = label.squeeze_(1).to(device)\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)  # Modelin çıktısı (logits)\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Test fonksiyonu\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for data, label in tqdm(loader, desc=\"Testing\", leave=False):\n",
    "        label = label.squeeze_(1).to(device)\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=1)  # En yüksek logit değerine sahip sınıf\n",
    "\n",
    "            y_true.extend(label.cpu().numpy())\n",
    "            y_pred.extend(pred.cpu().numpy())\n",
    "    return y_true, y_pred"
   ],
   "id": "aaa9e2ed30e83480",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T19:38:52.640481Z",
     "start_time": "2025-03-18T19:34:42.143152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_dict = {\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1\": [],\n",
    "    \"TP\": [],\n",
    "    \"TN\": [],\n",
    "    \"FP\": [],\n",
    "    \"FN\": []\n",
    "}\n",
    "\n",
    "model_name ='GraphResidualClassifier' #, 'GraphTransClassifier'\n",
    "print(\"Training Model: \", model_name)\n",
    "# Model, optimizer ve loss function tanımlanıyor\n",
    "\n",
    "if model_name == 'GraphClassifier':\n",
    "    model = GraphClassifier(input_dim=input_dim, hidden_dim_1=hidden_dim_1, hidden_dim_2=hidden_dim_2, output_dim=2).to(device)\n",
    "elif model_name == 'GraphLSTMClassifier':\n",
    "    model = GraphLSTMClassifier(input_dim=input_dim, hidden_dim_1=hidden_dim_1, hidden_dim_2=hidden_dim_2, lstm_hidden_dim=hidden_dim_3, output_dim=2).to(device)\n",
    "elif model_name == 'GraphTransClassifier':\n",
    "    model = GraphTransClassifier(input_dim=input_dim, hidden_dim_1=hidden_dim_1, hidden_dim_2=hidden_dim_2, nhead=4, num_encoder_layers=2, output_dim=2).to(device)\n",
    "elif model_name == 'GraphResidualClassifier':\n",
    "    model = GraphResidualClassifier(input_dim=input_dim, hidden_dim_1=hidden_dim_1, hidden_dim_2=hidden_dim_2, hidden_dim_3=hidden_dim_3, output_dim=2).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    " #Eğitim döngüsü\n",
    "num_epochs = 15\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train()\n",
    "    y_true_test, y_pred_test  = test(test_loader)\n",
    "    accuracy, precision, recall, f1, tp, tn, fp, fn = evaluate(y_true_test, y_pred_test)\n",
    "\n",
    "    if epoch % 3 == 0 or epoch == num_epochs or epoch == 1:\n",
    "        print(f\"Epoch: {epoch:02d}, Loss: {loss:.4f} | Test | Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1} | TP: {tp}, TN: {tn}, FP: {fp}, FN: {fn}\")\n",
    "\n",
    "# torch.save(model.state_dict(), f'./outputs/{model_name}.pth')\n",
    "result_dict['Model'].append(model_name)\n",
    "result_dict['Accuracy'].append(accuracy)\n",
    "result_dict['Precision'].append(precision)\n",
    "result_dict['Recall'].append(recall)\n",
    "result_dict['F1'].append(f1)\n",
    "result_dict['TP'].append(tp)\n",
    "result_dict['TN'].append(tn)\n",
    "result_dict['FP'].append(fp)\n",
    "result_dict['FN'].append(fn)\n",
    "\n",
    "result_df = pd.DataFrame(data=result_dict)\n",
    "\n",
    "# result_df.to_csv('./outputs/MergerGraphNet_results_15.csv', index=False)\n"
   ],
   "id": "e94c2e374c1f4d52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model:  GraphResidualClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 390.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 262.31 MiB is free. Including non-PyTorch memory, this process has 3.55 GiB memory in use. Of the allocated memory 2.60 GiB is allocated by PyTorch, and 857.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOutOfMemoryError\u001B[39m                          Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 32\u001B[39m\n\u001B[32m     30\u001B[39m num_epochs = \u001B[32m15\u001B[39m\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m1\u001B[39m, num_epochs + \u001B[32m1\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m     loss = \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     33\u001B[39m     y_true_test, y_pred_test  = test(test_loader)\n\u001B[32m     34\u001B[39m     accuracy, precision, recall, f1, tp, tn, fp, fn = evaluate(y_true_test, y_pred_test)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 19\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     17\u001B[39m data = data.to(device)\n\u001B[32m     18\u001B[39m optimizer.zero_grad()\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m out = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Modelin çıktısı (logits)\u001B[39;00m\n\u001B[32m     20\u001B[39m loss = criterion(out, label)\n\u001B[32m     21\u001B[39m loss.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/mergergraphnet-5CuCFj11-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/mergergraphnet-5CuCFj11-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/CS/Projects/MergerGraphNet/lib/model/graph_classifer.py:65\u001B[39m, in \u001B[36mGraphResidualClassifier.forward\u001B[39m\u001B[34m(self, data)\u001B[39m\n\u001B[32m     62\u001B[39m x, edge_index, batch = data.x, data.edge_index, data.batch\n\u001B[32m     64\u001B[39m gat_out1 = \u001B[38;5;28mself\u001B[39m.gat1(x, edge_index)\n\u001B[32m---> \u001B[39m\u001B[32m65\u001B[39m gcn_out1 = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgcn1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     66\u001B[39m x = torch.relu(gat_out1 + gcn_out1 + \u001B[38;5;28mself\u001B[39m.lin1(x))  \u001B[38;5;66;03m# Residual connection\u001B[39;00m\n\u001B[32m     67\u001B[39m \u001B[38;5;66;03m#x = F.dropout(x, p=self.dropout, training=self.training)\u001B[39;00m\n\u001B[32m     68\u001B[39m \n\u001B[32m     69\u001B[39m \u001B[38;5;66;03m# İkinci katman\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/mergergraphnet-5CuCFj11-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/mergergraphnet-5CuCFj11-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/mergergraphnet-5CuCFj11-py3.12/lib/python3.12/site-packages/torch_geometric/nn/conv/gcn_conv.py:263\u001B[39m, in \u001B[36mGCNConv.forward\u001B[39m\u001B[34m(self, x, edge_index, edge_weight)\u001B[39m\n\u001B[32m    260\u001B[39m x = \u001B[38;5;28mself\u001B[39m.lin(x)\n\u001B[32m    262\u001B[39m \u001B[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m263\u001B[39m out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m=\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    265\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.bias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    266\u001B[39m     out = out + \u001B[38;5;28mself\u001B[39m.bias\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/tmp/torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_dmrwdejw.py:209\u001B[39m, in \u001B[36mpropagate\u001B[39m\u001B[34m(self, edge_index, x, edge_weight, size)\u001B[39m\n\u001B[32m    200\u001B[39m             kwargs = CollectArgs(\n\u001B[32m    201\u001B[39m                 x_j=hook_kwargs[\u001B[33m'\u001B[39m\u001B[33mx_j\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m    202\u001B[39m                 edge_weight=hook_kwargs[\u001B[33m'\u001B[39m\u001B[33medge_weight\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m   (...)\u001B[39m\u001B[32m    205\u001B[39m                 dim_size=kwargs.dim_size,\n\u001B[32m    206\u001B[39m             )\n\u001B[32m    207\u001B[39m \u001B[38;5;66;03m# End Message Forward Pre Hook #########################################\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m209\u001B[39m out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    210\u001B[39m \u001B[43m    \u001B[49m\u001B[43mx_j\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mx_j\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    211\u001B[39m \u001B[43m    \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    212\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    214\u001B[39m \u001B[38;5;66;03m# Begin Message Forward Hook ###########################################\u001B[39;00m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch.jit.is_scripting() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_compiling():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/mergergraphnet-5CuCFj11-py3.12/lib/python3.12/site-packages/torch_geometric/nn/conv/gcn_conv.py:271\u001B[39m, in \u001B[36mGCNConv.message\u001B[39m\u001B[34m(self, x_j, edge_weight)\u001B[39m\n\u001B[32m    270\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmessage\u001B[39m(\u001B[38;5;28mself\u001B[39m, x_j: Tensor, edge_weight: OptTensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m271\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m x_j \u001B[38;5;28;01mif\u001B[39;00m edge_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[43medge_weight\u001B[49m\u001B[43m.\u001B[49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_j\u001B[49m\n",
      "\u001B[31mOutOfMemoryError\u001B[39m: CUDA out of memory. Tried to allocate 390.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 262.31 MiB is free. Including non-PyTorch memory, this process has 3.55 GiB memory in use. Of the allocated memory 2.60 GiB is allocated by PyTorch, and 857.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "result_dict = {\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1\": [],\n",
    "    \"TP\": [],\n",
    "    \"TN\": [],\n",
    "    \"FP\": [],\n",
    "    \"FN\": []\n",
    "}\n",
    "\n",
    "for model_name in ['GraphClassifier', 'GraphResidualClassifier', 'GraphLSTMClassifier']: #, 'GraphTransClassifier'\n",
    "    print(\"Training Model: \", model_name)\n",
    "    # Model, optimizer ve loss function tanımlanıyor\n",
    "\n",
    "    if model_name == 'GraphClassifier':\n",
    "        model = GraphClassifier(input_dim=input_dim, hidden_dim_1=hidden_dim_1, hidden_dim_2=hidden_dim_2, output_dim=2).to(device)\n",
    "    elif model_name == 'GraphLSTMClassifier':\n",
    "        model = GraphLSTMClassifier(input_dim=input_dim, hidden_dim_1=hidden_dim_1, hidden_dim_2=hidden_dim_2, lstm_hidden_dim=hidden_dim_3, output_dim=2).to(device)\n",
    "    elif model_name == 'GraphTransClassifier':\n",
    "        model = GraphTransClassifier(input_dim=input_dim, hidden_dim_1=hidden_dim_1, hidden_dim_2=hidden_dim_2, nhead=4, num_encoder_layers=2, output_dim=2).to(device)\n",
    "    elif model_name == 'GraphResidualClassifier':\n",
    "        model = GraphResidualClassifier(input_dim=input_dim, hidden_dim_1=hidden_dim_1, hidden_dim_2=hidden_dim_2, hidden_dim_3=hidden_dim_3, output_dim=2).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0002)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "     #Eğitim döngüsü\n",
    "    num_epochs = 15\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        loss = train()\n",
    "        y_true_test, y_pred_test  = test(test_loader)\n",
    "        accuracy, precision, recall, f1, tp, tn, fp, fn = evaluate(y_true_test, y_pred_test)\n",
    "\n",
    "        if epoch % 3 == 0 or epoch == num_epochs or epoch == 1:\n",
    "            print(f\"Epoch: {epoch:02d}, Loss: {loss:.4f} | Test | Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1} | TP: {tp}, TN: {tn}, FP: {fp}, FN: {fn}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f'./outputs/{model_name}.pth')\n",
    "    result_dict['Model'].append(model_name)\n",
    "    result_dict['Accuracy'].append(accuracy)\n",
    "    result_dict['Precision'].append(precision)\n",
    "    result_dict['Recall'].append(recall)\n",
    "    result_dict['F1'].append(f1)\n",
    "    result_dict['TP'].append(tp)\n",
    "    result_dict['TN'].append(tn)\n",
    "    result_dict['FP'].append(fp)\n",
    "    result_dict['FN'].append(fn)\n",
    "\n",
    "    result_df = pd.DataFrame(data=result_dict)\n",
    "\n",
    "    result_df.to_csv('./outputs/MergerGraphNet_results_15.csv', index=False)\n"
   ],
   "id": "f92def42164c9ec6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "    result_df.head()",
   "id": "ebbb8a2a6aaccb10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1e08c013b8faceaa",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
