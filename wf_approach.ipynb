{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-02T11:20:42.499625Z",
     "start_time": "2025-07-02T11:20:41.706023Z"
    }
   },
   "source": [
    "from lib.database.database_connector import DatabaseConnector\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/cagatay/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:20:42.582658Z",
     "start_time": "2025-07-02T11:20:42.580618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "database_connector = DatabaseConnector(\"./data/database.db\")\n",
    "cursor = database_connector.cursor\n",
    "\n",
    "split_date = \"2020-01-01\""
   ],
   "id": "28432f70c8e0ded3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:20:43.113941Z",
     "start_time": "2025-07-02T11:20:42.635502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = cursor.execute(\n",
    "    \"SELECT sentences, label FROM embeddings WHERE filing_date < '2020-01-01';\"\n",
    ").fetchall()\n",
    "\n",
    "test_data = cursor.execute(\n",
    "    \"SELECT sentences, label FROM embeddings WHERE filing_date >= '2020-01-01';\"\n",
    ").fetchall()"
   ],
   "id": "71e5a6d3141dd21e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:20:43.915269Z",
     "start_time": "2025-07-02T11:20:43.121897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = [(json.loads(sentences), label) for sentences, label in train_data]\n",
    "test_data = [(json.loads(sentences), label) for sentences, label in test_data]"
   ],
   "id": "a8c84f44a3aa6746",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:20:44.147395Z",
     "start_time": "2025-07-02T11:20:43.923913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = [(\" \".join(texts), label) for texts, label in train_data]\n",
    "test_data = [(\" \".join(texts), label) for texts, label in test_data]"
   ],
   "id": "e9f950700c58505",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:20:44.157745Z",
     "start_time": "2025-07-02T11:20:44.155393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess(text):\n",
    "    # Küçük harf, sadece harf ve boşluk\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in stop_words and len(t)>2]\n",
    "    return ' '.join(tokens)"
   ],
   "id": "d38022ebbfbce89b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:20:57.553382Z",
     "start_time": "2025-07-02T11:20:44.205286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = [(preprocess(text), label) for text, label in train_data]\n",
    "test_data = [(preprocess(text), label) for text, label in test_data]"
   ],
   "id": "960b8aa8a56ae905",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:21:35.216232Z",
     "start_time": "2025-07-02T11:20:57.561337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Bag-of-Words özelliklerini çıkarma\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=768,       # en sık 768 kelimeyi al\n",
    "    ngram_range=(1,2),       # unigram + bigram\n",
    "    min_df=5,                # en az 5 dokümanda geçsin\n",
    "    max_df=0.8               # en fazla %80 dokümanda geçsin\n",
    ")\n",
    "X_train = vectorizer.fit_transform([text for text, label in train_data])\n",
    "y_train = np.array([        label for text, label in train_data])\n",
    "X_test  = vectorizer.transform([text for text, label in test_data])\n",
    "y_test  = np.array([        label for text, label in test_data])"
   ],
   "id": "7ad4849c56fc4e94",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:21:40.675717Z",
     "start_time": "2025-07-02T11:21:35.227139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- Logistic Regression ----\n",
    "lr = LogisticRegression(max_iter=1000, n_jobs=-1, random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr   = lr.predict(X_test)\n",
    "y_proba_lr  = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(\"Accuracy:       \", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"Precision:      \", precision_score(y_test, y_pred_lr))\n",
    "print(\"Recall:         \", recall_score(y_test, y_pred_lr))\n",
    "print(\"F1-score:       \", f1_score(y_test, y_pred_lr))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_lr).ravel()\n",
    "print(\"TP: {:.3f}\".format(tp))\n",
    "print(\"TN: {:.3f}\".format(tn))\n",
    "print(\"FP: {:.3f}\".format(fp))\n",
    "print(\"FN: {:.3f}\".format(fn))"
   ],
   "id": "449a4756214b1369",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "Accuracy:        0.7964946445959105\n",
      "Precision:       0.23148148148148148\n",
      "Recall:          0.16556291390728478\n",
      "F1-score:        0.19305019305019305\n",
      "TP: 25.000\n",
      "TN: 793.000\n",
      "FP: 83.000\n",
      "FN: 126.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cagatay/.cache/pypoetry/virtualenvs/mergergraphnet-5CuCFj11-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:21:40.692807Z",
     "start_time": "2025-07-02T11:21:40.686990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# feature isimleri ve katsayılar\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefs = lr.coef_[0]\n",
    "\n",
    "# Pozitif sınıf lehine en güçlü 10 n-gram\n",
    "top_pos_idx = np.argsort(coefs)[-10:][::-1]\n",
    "print(\"Top 10 pozitife dönen n-gram’lar (label=1 lehine):\")\n",
    "for i in top_pos_idx:\n",
    "    print(f\"  {feature_names[i]:<20} coef = {coefs[i]:.4f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Negatif sınıf lehine en güçlü 10 n-gram\n",
    "top_neg_idx = np.argsort(coefs)[:10]\n",
    "print(\"Top 10 negatife dönen n-gram’lar (label=0 lehine):\")\n",
    "for i in top_neg_idx:\n",
    "    print(f\"  {feature_names[i]:<20} coef = {coefs[i]:.4f}\")"
   ],
   "id": "b4bad83a5149dcbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 pozitife dönen n-gram’lar (label=1 lehine):\n",
      "  balance sheet        coef = 0.2770\n",
      "  estate               coef = 0.1999\n",
      "  weighted average     coef = 0.1892\n",
      "  actual results       coef = 0.1867\n",
      "  equivalents          coef = 0.1647\n",
      "  either               coef = 0.1369\n",
      "  directors            coef = 0.1125\n",
      "  cash flow            coef = 0.1073\n",
      "  forward looking      coef = 0.0936\n",
      "  next                 coef = 0.0930\n",
      "\n",
      "Top 10 negatife dönen n-gram’lar (label=0 lehine):\n",
      "  sheet                coef = -0.2658\n",
      "  real estate          coef = -0.2371\n",
      "  weighted             coef = -0.1636\n",
      "  board directors      coef = -0.1508\n",
      "  cash equivalents     coef = -0.1423\n",
      "  characters           coef = -0.1355\n",
      "  numbers              coef = -0.1281\n",
      "  looking              coef = -0.1255\n",
      "  flow                 coef = -0.1254\n",
      "  accrued              coef = -0.1013\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:21:41.077268Z",
     "start_time": "2025-07-02T11:21:40.738812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf  = rf.predict(X_test)\n",
    "y_proba_rf = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"=== Random Forest Regression ===\")\n",
    "print(\"Accuracy:       \", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:      \", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:         \", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1-score:       \", f1_score(y_test, y_pred_rf))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
    "print(\"TP: {:.3f}\".format(tp))\n",
    "print(\"TN: {:.3f}\".format(tn))\n",
    "print(\"FP: {:.3f}\".format(fp))\n",
    "print(\"FN: {:.3f}\".format(fn))"
   ],
   "id": "5e17bb36ddd41ad3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Regression ===\n",
      "Accuracy:        0.8364167478091529\n",
      "Precision:       0.2571428571428571\n",
      "Recall:          0.059602649006622516\n",
      "F1-score:        0.0967741935483871\n",
      "TP: 9.000\n",
      "TN: 850.000\n",
      "FP: 26.000\n",
      "FN: 142.000\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:21:45.049078Z",
     "start_time": "2025-07-02T11:21:41.088270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_proba_knn = knn.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"=== KNN Regression ===\")\n",
    "print(\"Accuracy:       \", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Precision:      \", precision_score(y_test, y_pred_knn))\n",
    "print(\"Recall:         \", recall_score(y_test, y_pred_knn))\n",
    "print(\"F1-score:       \", f1_score(y_test, y_pred_knn))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
    "print(\"TP: {:.3f}\".format(tp))\n",
    "print(\"TN: {:.3f}\".format(tn))\n",
    "print(\"FP: {:.3f}\".format(fp))\n",
    "print(\"FN: {:.3f}\".format(fn))\n"
   ],
   "id": "e508b080285f14a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Regression ===\n",
      "Accuracy:        0.7867575462512172\n",
      "Precision:       0.19090909090909092\n",
      "Recall:          0.1390728476821192\n",
      "F1-score:        0.16091954022988506\n",
      "TP: 21.000\n",
      "TN: 787.000\n",
      "FP: 89.000\n",
      "FN: 130.000\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:21:45.114667Z",
     "start_time": "2025-07-02T11:21:45.112695Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "141874df9d11153b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
